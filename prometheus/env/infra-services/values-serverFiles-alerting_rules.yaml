serverFiles:
  ## Alerts configuration
  ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/
  alerting_rules.yml:
    groups:
      - name: Downtime
        rules:
        - alert: KubernetesPodNotHealthy
          expr: up{cloud_google_com_gke_preemptible!="true"} == 0 and sum by(namespace, pod) (kube_pod_status_phase{namespace!~"workflows.*|kube-system",phase=~"Pending|Unknown|Failed"}) > 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: Kubernetes Pod not healthy (instance {{ $labels.instance }})
            description: "Pod has been in a non-ready state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    
        - alert: KubernetesPodCrashLooping
          expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
          for: 2m
          labels:
            severity: warning
          annotations:
            summary: Kubernetes pod crash looping (instance {{ $labels.instance }})
            description: "Pod {{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

        - alert: statefulsetDown
          # Condition for alerting
          expr: up{cloud_google_com_gke_preemptible!="true", statefulset_kubernetes_io_pod_name !=""} == 0
          for: 1m
          # Annotation - additional informational labels to store more information
          annotations:
            title: 'Instance {{ $labels.instance }} down'
            description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minute.'
          # Labels - additional labels to be attached to the alert
          labels:
            severity: 'critical'

      - name: Containers
        rules:
        - alert: ContainerCpuUsage
          expr: ((sum(rate(container_cpu_usage_seconds_total{namespace!="", image!="", container!="POD", image!=""}[3m]))  by (pod) * 100)) > 70
          for: 5m
          labels:
            severity: 'critical'
          annotations:
            title: 'Container CPU usage (instance {{ $labels.namespace }}) {{ $labels.pod }}'
            description: 'Container CPU usage is above 70%'
        - alert: ContainerMemoryUsage
          expr: sum(rate(container_cpu_usage_seconds_total{namespace!=""}[5m])) by (pod) > 3.0e+09
          for: 5m
          labels:
            severity: 'critical'
          annotations:
            title: 'High Memory Usage'
            description: 'High Memory Usage (instance {{ $labels.namespace }}) {{ $labels.pod }}'
        - alert: ContainerRestarts
          expr: delta(kube_pod_container_status_restarts_total{namespace!=""}[1h]) >= 1
          for: 10s
          labels:
            severity: 'warning'
          annotations:
            summary: 'Containers are restarting'
            description: 'The container {{ $labels.container }} in pod {{ $labels.pod }}
              has restarted at least {{ humanize $value}} times in the last hour on instance
              {{ $labels.instance }}.'

      - name: K8S
        rules:
        - alert: NodeHighCpuLoad
          expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
          for: 10m
          labels:
            severity: 'critical'
          annotations:
            title: 'Host high CPU load (instance {{ $labels.instance }})'
            description: 'CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}'
        - alert: NodeOutOfMemory
          expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
          for: 5m
          labels:
            severity: 'critical'
          annotations:
            title: 'Host out of memory (instance {{ $labels.instance }})'
            description: 'Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}'

      - name: pg_mundi
        rules:
        - alert: pendingExecution
          expr: pg_mundi_invoice_advance_commands_count > 0
          for: 20m
          annotations:
            title: 'Invoice advance commands status: pendingExecution'
            description: 'db: mundi     schema: invoice_advance'
          labels:
            severity: 'warning'
      
      - name: pg_mundi_invoice_advance_request_failed
        rules:
        - alert: invoiceAdvanceRequestFailed
          expr: pg_mundi_invoice_advance_request_failed_count > 0
          for: 30m
          annotations:
            title: 'Invoice advance requests commands status: failed'
            description: 'Advance requests failed in the last 20 min'
          labels:
            severity: 'warning'            

      - name: ssl_expiry.rules 
        rules:
        ## Alert triggers on week days, between 12hs-18hs AR and 10hs-16hs CO, 30 days prior to cert expiration
        - alert: SSLCertExpiringSoon 
          expr: ssl_cert_not_after - time() < 86400 * 30 AND ON() (14 < hour() < 22) AND ON() (0 < day_of_week() < 6)
          for: 10m
          labels:
            severity: 'warning'
          annotations:
            title: 'SSL Certificate will expire in 30 days'
            description: 'SSL Certificate for {{ $labels.cn }} will expire in 30 days'
        ## Alert triggers on week days, between 12hs-18hs AR and 10hs-16hs CO, 14 days prior to cert expiration
        - alert: SSLCertExpiringVerySoon 
          expr: ssl_cert_not_after - time() < 86400 * 14 AND ON() (14 < hour() < 22) AND ON() (0 < day_of_week() < 6)
          for: 10m
          labels:
            severity: 'critical'
          annotations:
            title: 'SSL Certificate will expire in 14 days'
            description: 'SSL Certificate for {{ $labels.cn }} will expire in 14 days'

      - name: pg_alert_count_hasura_session_count
        rules:
        - alert: hasuraTokenDelete
          expr: pg_alert_count_hasura_session_count < 1
          for: 1m
          annotations:
            title: 'Hasura Token delete from database.'
            description: 'Check notion for workarround: https://www.notion.so/mundi/workaround-token-hasura-49983c48b91e403190c181281d84a811'
          labels:
            severity: 'critical'
